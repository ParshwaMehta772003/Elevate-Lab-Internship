import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import graphviz
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image # Import Image from PIL for displaying PNG

# --- 1. Data Preparation ---
print("--- 1. Data Preparation ---")
# Load the dataset
file_path = 'MultipleFiles/heart.csv'
df = pd.read_csv(file_path)

# Separate features (X) and target (y)
X = df.drop('target', axis=1)
y = df['target']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print("Data preparation complete.")
print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"y_test shape: {y_test.shape}")

# --- 2. Decision Tree Classifier ---
print("\n--- 2. Decision Tree Classifier ---")
# Train a Decision Tree Classifier (with max_depth=3 for visualization)
dt_classifier = DecisionTreeClassifier(max_depth=3, random_state=42)
dt_classifier.fit(X_train, y_train)

# Predict on the test set
y_pred_dt = dt_classifier.predict(X_test)

# Calculate accuracy
accuracy_dt = accuracy_score(y_test, y_pred_dt)
print(f"Decision Tree Classifier Accuracy (max_depth=3): {accuracy_dt:.4f}")

# Visualize the Decision Tree
# This will create a .png file.
# We set view=False to prevent the "no view rule" error.
# The image will be displayed using matplotlib instead.
try:
    dot_data = export_graphviz(dt_classifier,
                               out_file=None,
                               feature_names=X.columns,
                               class_names=['No Disease', 'Disease'],
                               filled=True, rounded=True,
                               special_characters=True)
    graph = graphviz.Source(dot_data)
    
    # Render the graph to a PNG file without trying to open it automatically
    png_file_name = "heart_decision_tree.png"
    graph.render(png_file_name.replace(".png", ""), format="png", view=False) # graphviz adds .png automatically

    print(f"Decision Tree visualization saved as '{png_file_name}'.")

    # Now, load the generated PNG and display it using matplotlib
    try:
        img = Image.open(png_file_name)
        plt.figure(figsize=(15, 10)) # Adjust figure size as needed
        plt.imshow(img)
        plt.axis('off') # Hide axes
        plt.title("Decision Tree Visualization")
        plt.show()
        print("Decision Tree visualization displayed using Matplotlib.")
    except FileNotFoundError:
        print(f"Error: Generated PNG file '{png_file_name}' not found. Check the path.")
    except Exception as e:
        print(f"Could not display image with matplotlib: {e}")

except Exception as e:
    print(f"Could not generate Decision Tree visualization. Error: {e}")
    print("Please ensure Graphviz is installed and configured correctly (e.g., added to system PATH).")


# --- 3. Analyze Overfitting and Control Tree Depth ---
print("\n--- 3. Analyze Overfitting and Control Tree Depth ---")
train_accuracies = []
test_accuracies = []
depths = range(1, 11) # Test depths from 1 to 10

for depth in depths:
    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)
    dt.fit(X_train, y_train)

    y_train_pred = dt.predict(X_train)
    y_test_pred = dt.predict(X_test)

    train_accuracies.append(accuracy_score(y_train, y_train_pred))
    test_accuracies.append(accuracy_score(y_test, y_test_pred))

# Plotting the results
plt.figure(figsize=(10, 6))
plt.plot(depths, train_accuracies, label='Training Accuracy', marker='o')
plt.plot(depths, test_accuracies, label='Testing Accuracy', marker='o')
plt.title('Decision Tree Accuracy vs. Max Depth')
plt.xlabel('Max Depth')
plt.ylabel('Accuracy')
plt.xticks(depths)
plt.legend()
plt.grid(True)
plt.show()
print("Analysis of overfitting with different tree depths complete. Check the plot.")


# --- 4. Random Forest Classifier ---
print("\n--- 4. Random Forest Classifier ---")
# Train a Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

# Predict on the test set
y_pred_rf = rf_classifier.predict(X_test)

# Calculate accuracy
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Random Forest Classifier Accuracy: {accuracy_rf:.4f}")

# Compare with Decision Tree accuracy
print(f"Decision Tree Classifier Accuracy (max_depth=3): {accuracy_dt:.4f}")
print(f"Random Forest Classifier Accuracy: {accuracy_rf:.4f}")

if accuracy_rf > accuracy_dt:
    print("Random Forest performed better than the Decision Tree (with max_depth=3).")
else:
    print("Decision Tree (with max_depth=3) performed better or equal to Random Forest.")


# --- 5. Interpret Feature Importances ---
print("\n--- 5. Interpret Feature Importances ---")
# Get feature importances
feature_importances = rf_classifier.feature_importances_
features = X.columns
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

print("Feature Importances from Random Forest:")
print(importance_df)

# Plotting feature importances
plt.figure(figsize=(12, 7))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importances in Random Forest Classifier')
plt.gca().invert_yaxis() # To display the most important feature at the top
plt.show()


# --- 6. Evaluate Using Cross-Validation ---
print("\n--- 6. Evaluate Using Cross-Validation ---")
# Decision Tree Cross-Validation
dt_cv_scores = cross_val_score(DecisionTreeClassifier(max_depth=3, random_state=42), X, y, cv=5, scoring='accuracy')
print(f"Decision Tree Cross-Validation Accuracies (max_depth=3): {dt_cv_scores}")
print(f"Mean Decision Tree Cross-Validation Accuracy (max_depth=3): {np.mean(dt_cv_scores):.4f}")
print(f"Standard Deviation of Decision Tree Cross-Validation Accuracy (max_depth=3): {np.std(dt_cv_scores):.4f}")

# Random Forest Cross-Validation
rf_cv_scores = cross_val_score(RandomForestClassifier(n_estimators=100, random_state=42), X, y, cv=5, scoring='accuracy')
print(f"\nRandom Forest Cross-Validation Accuracies: {rf_cv_scores}")
print(f"Mean Random Forest Cross-Validation Accuracy: {np.mean(rf_cv_scores):.4f}")
print(f"Standard Deviation of Random Forest Cross-Validation Accuracy: {np.std(rf_cv_scores):.4f}")

print("\n--- Task Complete ---")
